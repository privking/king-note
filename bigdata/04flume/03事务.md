# Flume事务

![image-20201024210506311](https://raw.githubusercontent.com/privking/king-note-images/master/img/note/image-20201024210506311-1603544706-36a958.png)

- batchSize:  

  - 每个Source和Sink都可以配置一个batchSize的参数。这个参数代表一次性到channel中put|take 多少个event。batchSize <=  transactionCapacity
  - `tier1.sources.source1.batchSize = 50`

- transactionCapacity：

  - putList和takeList的初始值！

  - `a1.channels.c1.transactionCapacity = 100`
  
- capacity： 

  - channel中存储event的容量大小！ transactionCapacity <=  capacity
  - `a1.channels.c1.capacity = 1000`

- putList: 
  -  source在向channel放入数据时的缓冲区
  - putList在初始化时，需要根据一个固定的size初始化，这个size在channel中设置！
  - 在channel中，这个size由参数transactionCapacity决定
  
- put事务流程：
  - source将封装好的event，先放入到putList中，放入完成后，一次性commit(),这批event就可以写入到channel!
  - 写入完成后，清空putList，开始下一批数据的写入
  - 假如一批event中的某些event在放入putList时，发生了异常，此时要执行rollback(),rollback()直接清空putList
- takeList: 

  - sink在向channel拉取数据时的缓冲区

- take事务流程

  -  sink不断从channel中拉取event，没拉取一个event，这个event会先放入takeList中
  - 当一个batchSize的event全部拉取到takeList中之后，此时由sink执行写出处理
  - 假如在写出过程中，发送了异常，此时执行回滚！将takeList中所有的event全部回滚到channel。反之，如果写出没有异常，执行commit(),清空takeList
  - 可能出现数据重复 在执行一半时回滚

## Flume采集数据会丢失吗

根据Flume的架构原理，Flume是不可能丢失数据的，其内部有完善的事务机制，Source到Channel是事务性的，Channel到Sink是事务性的，因此这两个环节不会出现数据的丢失，唯一可能丢失数据的情况是Channel采用memoryChannel，agent宕机导致数据丢失，或者Channel存储数据已满，导致Source不再写入，未写入的数据丢失。

Flume不会丢失数据，但是有可能造成数据的重复，例如数据已经成功由Sink发出，但是没有接收到响应，Sink会再次发送数据，此时可能会导致数据的重复。

## Flume的事务机制

Flume的事务机制（类似数据库的事务机制）：Flume使用两个独立的事务分别负责从Soucrce到Channel，以及从Channel到Sink的事件传递。比如spooling directory source 为文件的每一行创建一个事件，`一旦事务中所有的事件全部传递到Channel且提交成功，那么Soucrce就将该文件标记为完成`。同理，事务以类似的方式处理从Channel到Sink的传递过程，如果因为某种原因使得事件无法记录，那么事务将会回滚。且所有的事件都会保持到Channel中，等待重新传递