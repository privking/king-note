# 分区器

对于只存储 value的 RDD, 不需要分区器.

只有存储Key-Value类型的才会需要分区器.

Spark 目前支持 Hash 分区和 Range 分区，用户也可以自定义分区.

Hash 分区为当前的默认分区，Spark 中分区器直接决定了 RDD 中分区的个数、RDD 中每条数据经过 Shuffle 过程后属于哪个分区和 Reduce 的个数

## HashPartitioner

HashPartitioner分区的原理：对于给定的key，计算其hashCode，并除以分区的个数取余，如果余数小于 0，则用余数+分区的个数（否则加0），最后返回的值就是这个key所属的分区ID

可能导致每个分区中**数据量的不均匀**，极端情况下会导致某些分区拥有 RDD 的全部数据。

## RangePartitioner

将一定范围内的数映射到某一个分区内，**尽量保证每个分区中数据量的均匀，而且分区与分区之间是有序的**，一个分区中的元素肯定都是比另一个分区内的元素小或者大，但是分区内的元素是不能保证顺序的。简单的说就是将一定范围内的数映射到某一个分区内

第一步：先从整个 RDD 中**抽取出样本数据，将样本数据排序，计算出每个分区的最大 key 值，形成一个Array[KEY]类型的数组变量 rangeBounds；(边界数组).**

第二步：判断key在rangeBounds中所处的范围，给出该key值在下一个RDD中的分区id下标；该分区器要求 RDD 中的 KEY 类型必须是可以排序的.

比如[1,100,200,300,400]，然后对比传进来的key，返回对应的分区id。

## 自定义分区器

继承 org.apache.spark.Partitioner, 并且需要实现下面的方法:

- numPartitions
  - 该方法需要返回分区数, 必须要大于0.
- getPartition(key)
  - 返回指定键的分区编号(0到numPartitions-1)。
- equals
  -  Java 判断相等性的标准方法。这个方法的实现非常重要，Spark 需要用这个方法来检查你的分区器对象是否和其他分区器实例相同，这样 Spark 才可以判断两个 RDD 的分区方式是否相同
- hashCode
  - 如果你覆写了equals, 则也应该覆写这个方法.

